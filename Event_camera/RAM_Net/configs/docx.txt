# Config:
e = event base
ergb_no_recurrent = event + rgb + no recurrent          
baseline ergb = event + rgb baseline
rgb = rgb base
ergb = event + rgb RAMNET

In the following you can find explanations of different parameters in the config whose meaning is not apparent by the name.
= 파라미터 명으로는 가시적이지 않음. 그럼 알려줘야할 거 아니야!!!

### name: 
The checkpoint will be saved under this name in the specified save directory (trainer, save_dir). Make sure that there does not exist a checkpoint at this location with the same name yet, otherwise it will not work.
= 체크포인트 폴더가 이미 존재하면 작동하지 않음.

## dataloader:
### type:
Specifies the type of dataloader, either SequenceMVSEC or SequenceSynchronizedFramesEventsDataset can be used.
= MVSEC도 되고, Frame & Event dataset도 된다는 얘기인가

### type2:
For the branch `asynchronous_irregular_real_data` a second dataset can be specified in order to train on two datasets simultaneously. Also specify the base_folder2 and step_size2 if this is used.
= `asynchronous_irregular_real_data` 이 데이터셋 or 브랜치를 위한 파라미터

### base_folder:
specify the path of the data folder, starting from the exported path (see README in AMM-Net folder)
= 데이터 폴더 패스

### step_size:
specifies the number of skipped datapoints before beginning a new sequence. If sequence = 5 and step_size = 5, each datapoint is only seen one during an epoch. If the the step_size is smaller than the sequence_length, datapoints are seen several times. However, step_size > 0 does not actually skip image frames that the network sees, it only defines where a new sequence should be start with respect to the starting data point from the last sequence.
= step_size는 네트워크에 투입되는 Frame 인터벌을 의미함. 일반적으로 5로 하는 듯.

### clip_distance:
Defines the max seen depth used to calculate metric depth from log depth. When training a network for further use in MVSEC, the same clip_distance as in MVSEC should be used for the training in simulation (=3.70378).
= 깊이 추정할 때, 계산하고자 하는 범위의 max log depth값. 일반적으로 MVSEC 기준 3.70378을 사용하는 듯하다.

### every_x_rgb_frames:
defines how many rgb frames are skipped in order to get asynchronous data read in. should be equal to 1 if baseline = "ergb0" / "e", otherwise events are skipped.
= ??? step_size랑 비슷하게 몇 개의 rgb frame을 생략하고 데이터를 받아들일지 사용. 하지만, "ergb0", "e"일 떄는 1로 설정해야함. 그렇지 않으면 event가 스킵됨.?

### scale_factor:
downscales inputs for faster training.
= 빠른 학습을 위한 이미지 다운샘플링 팩터.

### baseline:
If `false`, AMM-Net is trained. Other options are `rgb`, `e`, `ergb0`. For the `asynchronous_irregular_real_data` branch only `false` and `rgb` can be used.
= 일반적으로 False로 되어있으면, RAM-Net이 학습됨. 이외로는 [rgb, e, ergb0] 등이 있음. 그런데, `asynchronous_irregular_real_data` 브랜치에서는 [False, rgb]만 됨.


## trainer:
### loss_combination 
Defines which predictions are used to calculate the loss. It can be false (=use loss of all inputs of the network, e.g. events0, events1, events2, ..., image), or can be a list of the inputs that should be used, e.g. simply "image" or ["image", "events5"].
For the branch `asynchronous_irregular_real_data`, ["image_last", "events_last"] should be used as depth data is not available at intermediate timesteps.
For the baselines in simulation, it should be equal to "image".
= 손실 함수 조합 혹은 구간을 결정하는 인자로, False이면 모든 입력 구간에 대해 loss를 계산하고, simply "image" or ["image", "events5"]와 같이 특정 구간을 입력하면 해당 구간에서만 계산한다. `asynchronous_irregular_real_data` 브랜치의 경우, ["image_last", "events_last"]ㄹ오 국한되어야한다. 왜냐하면 depth data가 중간 타임스탬프에서 이용 불가능하기 때문에. 그리고 일반적으로 Baseline에서는 "image"로 통일한다.

## model:
### state_combination:
"convgru" and "convlstm" can be used. Defines how the state update is performed.
For the baselines, it should be defined as "convlstm", this will be the recurrent layer in the encoder.
= 상태 업데이트를 어떤 블록 기반으로 결정할 지 고르는 인자로 "convgru" and "convlstm" 두 경우가 있다. 베이스라인의 경우, "convlstm"으로 고정한다.

### spatial_resolution:
Only needed for the use with phased LSTM to properly load the model at test time. However, as phased LSTM is not used in the tested configurations, this could be omitted.



